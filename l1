Deep learning 

Neural Network is an algorithm that is used for classification problems involving many features and complex decision boundaries.
Given two features x1 and x2 and the task of assigning a label y(0,1) to the dataset of x1,x2 values, the decision boundary can be written as
w1x1 + w2x2 + b = 0
or Wx + b = 0 where W= (w1,w2) and x = (x1,x2)
  the prediction y` = {1 if Wx + b >=0 , 0 otherwise}
  
  Perceptrons - equivalent to neurons in the brain.
  
        w1  
  (x1)------>|--------|
        w2   |   f =  |      |----------|
  (x2)------>|  Wx+b  |----->|    s =   |----->y`     
        b    |        |      |f>=0 ?1 :0|
  (1)------->|--------|
  
  
Perceptron algorithm
  Ex - 2x1
  



  import numpy as np
  
  def stepFunction(t):
    if t >= 0:
        return 1
    return 0

  def prediction(X, W, b):
    return stepFunction((np.matmul(X,W)+b)[0])

  def perceptronStep(X, y, W, b, learn_rate = 0.01):
    for i in range(len(X)):
        y_hat = prediction(X[i],W,b)
        for j in range(len(X[i])):
            if y[i]-y_hat==1:
                W[j] += X[i][j]*learn_rate
                W[j] += X[i][j]*learn_rate
                b += learn_rate
            elif y[i]-y_hat==-1:
                W[j] -= X[i][j]*learn_rate
                W[j] -= X[i][j]*learn_rate
                b -=learn_rate
    return W, b
    
  def trainPerceptronAlgorithm(X, y, learn_rate = 0.01, num_epochs = 25):
    W = np.array(np.random.rand(2,1))
    b = np.random.rand(1)[0] + x_max
    for i in range(num_epochs):
        W, b = perceptronStep(X, y, W, b, learn_rate)
    return 
  
